---
layout: page
title: Probability Distributions | Hypothesis Testing
description: Investigation of ideas through statistics
image: nil
nav-menu: false
show_tile: false
---

<a href="binomial.html" class="button small">Binomial</a>
<a href="poisson.html" class="button small">Poisson</a>
<a href="normal" class="button small">Normal</a>
<a href="charts" class="button small">Charts</a>
<a href="hypothesis-testing.html" class="button special small">Hypothesis Testing</a>

<a href="/quality-management">&#x2190; Back to Quality Management</a>

## Hypothesis Testing

Hypothesis testing is a formal procedure for testing theories using statistics. It is most often used by scientists to test specific hypotheses arising from such theories.

The five primary steps in hypothesis testing include:

- Stating your research hypothesis as a `null hypothesis (Ho)` and `alternate hypothesis (Ha or H1)`.
- Collecting data specifically designed to test the hypothesis.
- Performing an appropriate statistical test.
- Deciding whether to `reject` or `fail to reject` your `null hypothesis`.
- Presenting the findings within your `results and discussion` section.
- Though specific details may vary, the procedure you use when testing a hypothesis always follows some version of these steps.

# Performing Appropriate Statistical Test

There are a variety of statistical tests available, but they are all based on the comparison of `within-group variance` (how spread out the data is within a category) versus `between-group variance` (how different the categories are from one another).

If the `between-group variance` is large enough that there is little or no overlap between groups, then your statistical test will reflect that by showing a low `p-value`. This means it is unlikely that the differences between these groups came about by chance.

Alternatively, if there is high `within-group variance` and low `between-group variance`, then your statistical test will reflect that with a high `p-value`. This means it is likely that any difference you measure between groups is due to chance.

Your choice of statistical test will be based on the type of data you collected.

# Reject or Fail-to-Reject Your Null Hypothesis

Based on the outcome of your statistical test, you will have to decide whether to `reject` or `fail to reject` your null hypothesis.

In most cases you will use the `p-value` generated by your statistical test to guide your decision. And in most cases, your predetermined level of significance for rejecting the null hypothesis will be `0.05` – that is, when there is a less than 5% chance that you would see these results if the null hypothesis were true.

In some cases, researchers choose a more conservative level of significance, such as `0.01` (1%). This minimizes the risk of incorrectly rejecting the null hypothesis (Type I error).

# Presenting Your Findings

The results of hypothesis testing will be presented in the `results and discussion` sections of your research paper.

In the `results` section you should give a brief summary of the data and a summary of the results of your statistical test (for example, the estimated difference between group means and associated `p-value`). In the discussion, you can discuss whether your initial hypothesis was supported by your results or not.

In the formal language of hypothesis testing, we talk about rejecting or failing to reject the null hypothesis. You will probably be asked to do this in your statistics assignments.

However, when presenting research results in academic papers we rarely talk this way. Instead, we go back to our alternate hypothesis and state whether the result of our test was consistent or inconsistent with the alternate hypothesis.

If your null hypothesis was rejected, this result is interpreted as being consistent with your alternate hypothesis.

You might notice that we don’t say that we `reject` or `fail to reject` the alternate hypothesis. This is because hypothesis testing is not designed to prove or disprove anything. It is only designed to test whether a pattern we measure could have arisen spuriously, or by chance.

If we reject the null hypothesis based on our research (i.e., we find that it is unlikely that the pattern arose by chance), then we can say our test lends support to our hypothesis. But if the pattern does not pass our decision rule, meaning that it could have arisen by chance, then we say the test is inconsistent with our hypothesis.

<a href="/quality-management">&#x2190; Back to Quality Management</a>
